{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from adjustText import adjust_text\n",
    "\n",
    "metrics_to_use = [\"student_model_name\", \"T\", \"bs\", \"loss_ratio\", \n",
    "                  \"conditional\", \"curriculum\", \"cosine_decay\",\n",
    "                  \"inference_speed\", \"student_memory\", \"student_num_params\", #\"batch_time\", \n",
    "                  \"train_loss\", \"val_loss\", \"train_acc\", \"val_acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all JSONs from results folder\n",
    "json_files = glob.glob('./results/*.json')\n",
    "json_file_names = [os.path.basename(file) for file in json_files]\n",
    "\n",
    "# print(json_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = []\n",
    "\n",
    "# Read result files separately for teacher and students\n",
    "for file in json_files:\n",
    "    with open(file, 'r') as json_file:\n",
    "        if \"vgg16\" not in file:\n",
    "            data = json.load(json_file)\n",
    "            json_data.append(data)\n",
    "        else:\n",
    "            teacher_data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_epochs': 20,\n",
       " 'lr': 0.001,\n",
       " 'bs': 256,\n",
       " 'weight_decay': 0,\n",
       " 'student_model_name': 'mobilenet-V3-large',\n",
       " 'train_dir': 'real_data',\n",
       " 'val_dir': 'val',\n",
       " 'n_classes': 4,\n",
       " 'T': 1,\n",
       " 'loss_ratio': 0,\n",
       " 'greyscale': False,\n",
       " 'pretrained': False,\n",
       " 'train_split': 0.8,\n",
       " 'teacher_model_name': 'vgg16',\n",
       " 'finetuned': False,\n",
       " 'filename': 'vgg16-best-0.99625-lr;0.001-bs;256-weight_decay;0-train_dir;real_data-val_dir;val-finetuned;False',\n",
       " 'train_speed': [1335.5513310432434,\n",
       "  991.1837334632874,\n",
       "  1100.7363047599792,\n",
       "  993.4505326747894,\n",
       "  1146.4777796268463,\n",
       "  926.1254060268402,\n",
       "  909.82905626297,\n",
       "  671.4268491268158,\n",
       "  923.6541693210602,\n",
       "  310.7889451980591,\n",
       "  19.133223056793213,\n",
       "  19.15027165412903,\n",
       "  19.119204998016357,\n",
       "  19.119487047195435,\n",
       "  19.153185844421387,\n",
       "  19.169601917266846,\n",
       "  19.171563386917114,\n",
       "  19.165995597839355,\n",
       "  19.161134243011475,\n",
       "  19.161447048187256],\n",
       " 'inference_speed': [336.93229842185974,\n",
       "  239.85932970046997,\n",
       "  218.39346146583557,\n",
       "  240.37179470062256,\n",
       "  268.5185589790344,\n",
       "  198.88511872291565,\n",
       "  215.1515724658966,\n",
       "  217.84340906143188,\n",
       "  165.39844727516174,\n",
       "  5.108205795288086,\n",
       "  4.2046637535095215,\n",
       "  4.206905841827393,\n",
       "  4.205742120742798,\n",
       "  4.211906671524048,\n",
       "  4.2100465297698975,\n",
       "  4.205921649932861,\n",
       "  4.204833507537842,\n",
       "  4.205763339996338,\n",
       "  4.198996543884277,\n",
       "  4.2069313526153564],\n",
       " 'student_memory': 512.2214508056641,\n",
       " 'student_num_params': 134275780,\n",
       " 'train_loss': [4.052803652513088,\n",
       "  0.03355210765778106,\n",
       "  0.027346100967035304,\n",
       "  0.024542951191376363,\n",
       "  0.024500402631428168,\n",
       "  0.022750529151751984,\n",
       "  0.020762177959930305,\n",
       "  0.01874608990061572,\n",
       "  0.022518573488032788,\n",
       "  0.021283346561510687,\n",
       "  0.01631953934687475,\n",
       "  0.018096782837885107,\n",
       "  0.02245731488088792,\n",
       "  0.01900887249241944,\n",
       "  0.017709001269172495,\n",
       "  0.01910833300080041,\n",
       "  0.016945353481082285,\n",
       "  0.014894831951467643,\n",
       "  0.01914380423781671,\n",
       "  0.012928658934859933],\n",
       " 'val_loss': [0.025727634271606802,\n",
       "  0.021654438157565892,\n",
       "  0.020153148190584034,\n",
       "  0.018316505160182715,\n",
       "  0.022522572248708458,\n",
       "  0.014889590512029826,\n",
       "  0.01570249087177217,\n",
       "  0.013258351739495992,\n",
       "  0.015794962401269003,\n",
       "  0.014601241196505726,\n",
       "  0.013895999524975196,\n",
       "  0.020683421194553374,\n",
       "  0.011994006118766266,\n",
       "  0.012401136871194467,\n",
       "  0.010634159877663479,\n",
       "  0.018637166004627944,\n",
       "  0.010218074586009606,\n",
       "  0.010428309548879043,\n",
       "  0.011179916530381888,\n",
       "  0.009958957340422785],\n",
       " 'train_acc': [0.934328939841718,\n",
       "  0.9895169005102041,\n",
       "  0.9915497448979592,\n",
       "  0.9919660571886568,\n",
       "  0.9917667587192691,\n",
       "  0.9923247944335548,\n",
       "  0.9935427295918368,\n",
       "  0.9936224489795918,\n",
       "  0.9931042729591837,\n",
       "  0.9930644132653061,\n",
       "  0.9945790816326531,\n",
       "  0.9940387612702896,\n",
       "  0.9926259566326531,\n",
       "  0.9935825892857143,\n",
       "  0.9949776785714286,\n",
       "  0.9945170775968202,\n",
       "  0.9949776785714286,\n",
       "  0.9954338505560038,\n",
       "  0.994295634785477,\n",
       "  0.995735012755102],\n",
       " 'val_acc': [0.9909184432029724,\n",
       "  0.9929496932029724,\n",
       "  0.9918559432029724,\n",
       "  0.9934374976158142,\n",
       "  0.9920121932029724,\n",
       "  0.9943559432029724,\n",
       "  0.9939062476158143,\n",
       "  0.9957621932029724,\n",
       "  0.9932621932029724,\n",
       "  0.9949999976158143,\n",
       "  0.9952934432029724,\n",
       "  0.9926371932029724,\n",
       "  0.9956249976158142,\n",
       "  0.9957812476158142,\n",
       "  0.9954496932029724,\n",
       "  0.9937499976158142,\n",
       "  0.9962499976158142,\n",
       "  0.9960937476158143,\n",
       "  0.9957621932029724,\n",
       "  0.9959374976158142],\n",
       " 'F1_score': [],\n",
       " 'batch_time': 0.00531458854675293,\n",
       " 'hard_preds': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  ...],\n",
       " 'labels': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  ...],\n",
       " 'inference_batch_time': 0.0014064311981201172}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_data[\"student_model_name\"] = \"teacher_model\"\n",
    "# last loss/acc\n",
    "teacher_data[\"train_loss\"] = teacher_data[\"train_loss\"][-1]\n",
    "teacher_data[\"train_acc\"] = teacher_data[\"train_acc\"][-1]\n",
    "# min inference speed\n",
    "teacher_data[\"inference_speed\"] = min(teacher_data[\"inference_speed\"])\n",
    "# teacher_data[\"inference_speed\"] = teacher_data[\"batch_time\"]\n",
    "teacher_data[\"val_loss\"] = teacher_data[\"val_loss\"][-1]\n",
    "teacher_data[\"val_acc\"] = teacher_data[\"val_acc\"][-1]\n",
    "teacher_data = [{key: teacher_data.get(key, False) for key in metrics_to_use}]\n",
    "# teacher_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return only key:values that are used for plotting\n",
    "json_data = [{key: report.get(key, False) for key in metrics_to_use} for report in json_data]\n",
    "# json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data\n",
    "# last loss/acc and min inference speed\n",
    "for report in json_data:\n",
    "    for key, value in report.items():\n",
    "        # if isinstance(value, list):\n",
    "        if key in ['train_loss', 'train_acc', 'val_loss', 'val_acc']:\n",
    "            new_value = value[-1]\n",
    "            report[key] = new_value\n",
    "        if key == 'inference_speed':\n",
    "            new_value = min(value)\n",
    "            report[key] = new_value\n",
    "\n",
    "# json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join teacher result with student results\n",
    "full_json = (teacher_data + json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 21)\n",
      "    student_model_name                                    full_model_name  \\\n",
      "0        teacher_model                                      Teacher model   \n",
      "1             ghostnet  ghostnet_T=1_lossr=0.0_cond=False_curr=False_c...   \n",
      "2             ghostnet  ghostnet_T=2_lossr=0.5_cond=False_curr=False_c...   \n",
      "3             ghostnet  ghostnet_T=4_lossr=0.5_cond=True_curr=False_co...   \n",
      "4             ghostnet  ghostnet_T=4_lossr=0.5_cond=False_curr=False_c...   \n",
      "5             ghostnet  ghostnet_T=6_lossr=0.5_cond=False_curr=False_c...   \n",
      "6             ghostnet  ghostnet_T=4_lossr=0.5_cond=False_curr=True_co...   \n",
      "7             ghostnet  ghostnet_T=4_lossr=0.5_cond=False_curr=True_co...   \n",
      "8   mobilenet-V3-large  mobilenet-V3-large_T=1_lossr=0.0_cond=False_cu...   \n",
      "9   mobilenet-V3-large  mobilenet-V3-large_T=4_lossr=0.5_cond=False_cu...   \n",
      "10  mobilenet-V3-large  mobilenet-V3-large_T=6_lossr=0.5_cond=False_cu...   \n",
      "11  mobilenet-V3-large  mobilenet-V3-large_T=4_lossr=0.5_cond=True_cur...   \n",
      "12  mobilenet-V3-large  mobilenet-V3-large_T=2_lossr=0.5_cond=False_cu...   \n",
      "13  mobilenet-V3-small  mobilenet-V3-small_T=1_lossr=0.0_cond=False_cu...   \n",
      "14  mobilenet-V3-small  mobilenet-V3-small_T=2_lossr=0.5_cond=False_cu...   \n",
      "15  mobilenet-V3-small  mobilenet-V3-small_T=4_lossr=0.5_cond=False_cu...   \n",
      "16  mobilenet-V3-small  mobilenet-V3-small_T=4_lossr=0.5_cond=True_cur...   \n",
      "17  mobilenet-V3-small  mobilenet-V3-small_T=4_lossr=0.5_cond=False_cu...   \n",
      "18  mobilenet-V3-small  mobilenet-V3-small_T=6_lossr=0.5_cond=False_cu...   \n",
      "19  mobilenet-V3-small  mobilenet-V3-small_T=4_lossr=0.5_cond=False_cu...   \n",
      "20          shufflenet  shufflenet_T=1_lossr=0.0_cond=False_curr=False...   \n",
      "21          shufflenet  shufflenet_T=4_lossr=0.5_cond=False_curr=True_...   \n",
      "22          shufflenet  shufflenet_T=4_lossr=0.5_cond=False_curr=True_...   \n",
      "23          shufflenet  shufflenet_T=4_lossr=0.5_cond=True_curr=False_...   \n",
      "24          shufflenet  shufflenet_T=4_lossr=0.5_cond=False_curr=False...   \n",
      "25          shufflenet  shufflenet_T=2_lossr=0.5_cond=False_curr=False...   \n",
      "26          shufflenet  shufflenet_T=6_lossr=0.5_cond=False_curr=False...   \n",
      "\n",
      "                                       model_name  \\\n",
      "0                                   Teacher model   \n",
      "1                          ghostnet T=1 lossr=0.0   \n",
      "2                          ghostnet T=2 lossr=0.5   \n",
      "3                               ghostnet T=4 Cond   \n",
      "4                          ghostnet T=4 lossr=0.5   \n",
      "5                          ghostnet T=6 lossr=0.5   \n",
      "6             ghostnet Curr + Lin decay lossr=0.5   \n",
      "7             ghostnet Curr + Cos decay lossr=0.5   \n",
      "8                mobilenet-V3-large T=1 lossr=0.0   \n",
      "9                mobilenet-V3-large T=4 lossr=0.5   \n",
      "10               mobilenet-V3-large T=6 lossr=0.5   \n",
      "11                    mobilenet-V3-large T=4 Cond   \n",
      "12               mobilenet-V3-large T=2 lossr=0.5   \n",
      "13               mobilenet-V3-small T=1 lossr=0.0   \n",
      "14               mobilenet-V3-small T=2 lossr=0.5   \n",
      "15               mobilenet-V3-small T=4 lossr=0.5   \n",
      "16                    mobilenet-V3-small T=4 Cond   \n",
      "17  mobilenet-V3-small Curr + Lin decay lossr=0.5   \n",
      "18               mobilenet-V3-small T=6 lossr=0.5   \n",
      "19  mobilenet-V3-small Curr + Cos decay lossr=0.5   \n",
      "20                       shufflenet T=1 lossr=0.0   \n",
      "21          shufflenet Curr + Lin decay lossr=0.5   \n",
      "22          shufflenet Curr + Cos decay lossr=0.5   \n",
      "23                            shufflenet T=4 Cond   \n",
      "24                       shufflenet T=4 lossr=0.5   \n",
      "25                       shufflenet T=2 lossr=0.5   \n",
      "26                       shufflenet T=6 lossr=0.5   \n",
      "\n",
      "                hyperparameters  T   bs  loss_ratio  conditional  curriculum  \\\n",
      "0                 Teacher model  1  256         0.0        False       False   \n",
      "1                 T=1 lossr=0.0  1  256         0.0        False       False   \n",
      "2                 T=2 lossr=0.5  2  256         0.5        False       False   \n",
      "3                      T=4 Cond  4  256         0.5         True       False   \n",
      "4                 T=4 lossr=0.5  4  256         0.5        False       False   \n",
      "5                 T=6 lossr=0.5  6  256         0.5        False       False   \n",
      "6    Curr + Lin decay lossr=0.5  4  256         0.5        False        True   \n",
      "7    Curr + Cos decay lossr=0.5  4  256         0.5        False        True   \n",
      "8                 T=1 lossr=0.0  1  256         0.0        False       False   \n",
      "9                 T=4 lossr=0.5  4  256         0.5        False       False   \n",
      "10                T=6 lossr=0.5  6  256         0.5        False       False   \n",
      "11                     T=4 Cond  4  256         0.5         True       False   \n",
      "12                T=2 lossr=0.5  2  256         0.5        False       False   \n",
      "13                T=1 lossr=0.0  1  256         0.0        False       False   \n",
      "14                T=2 lossr=0.5  2  256         0.5        False       False   \n",
      "15                T=4 lossr=0.5  4  256         0.5        False       False   \n",
      "16                     T=4 Cond  4  256         0.5         True       False   \n",
      "17   Curr + Lin decay lossr=0.5  4  256         0.5        False        True   \n",
      "18                T=6 lossr=0.5  6  256         0.5        False       False   \n",
      "19   Curr + Cos decay lossr=0.5  4  256         0.5        False        True   \n",
      "20                T=1 lossr=0.0  1  256         0.0        False       False   \n",
      "21   Curr + Lin decay lossr=0.5  4  256         0.5        False        True   \n",
      "22   Curr + Cos decay lossr=0.5  4  256         0.5        False        True   \n",
      "23                     T=4 Cond  4  256         0.5         True       False   \n",
      "24                T=4 lossr=0.5  4  256         0.5        False       False   \n",
      "25                T=2 lossr=0.5  2  256         0.5        False       False   \n",
      "26                T=6 lossr=0.5  6  256         0.5        False       False   \n",
      "\n",
      "    cosine_decay  ...                                         batch_time  \\\n",
      "0          False  ...                                           0.005315   \n",
      "1          False  ...  [0.2051987648010254, 0.21124255657196045, 0.21...   \n",
      "2          False  ...  [0.20403850078582764, 0.2036837339401245, 0.20...   \n",
      "3          False  ...  [0.21213257312774658, 0.21213173866271973, 0.2...   \n",
      "4          False  ...  [0.20326900482177734, 0.202905535697937, 0.202...   \n",
      "5          False  ...  [0.21043646335601807, 0.20961856842041016, 0.2...   \n",
      "6          False  ...  [0.1909266710281372, 0.18985962867736816, 0.19...   \n",
      "7           True  ...  [0.19584941864013672, 0.19604134559631348, 0.1...   \n",
      "8          False  ...                                           0.167902   \n",
      "9          False  ...  [0.17775177955627441, 0.17780804634094238, 0.1...   \n",
      "10         False  ...                                           0.180396   \n",
      "11         False  ...  [0.18234217166900635, 0.18195736408233643, 0.1...   \n",
      "12         False  ...                                           0.181629   \n",
      "13         False  ...                                           0.123445   \n",
      "14         False  ...                                           0.139203   \n",
      "15         False  ...                                           0.124599   \n",
      "16         False  ...  [0.15323984622955322, 0.14580857753753662, 0.1...   \n",
      "17         False  ...  [0.15324199199676514, 0.1523573398590088, 0.15...   \n",
      "18         False  ...                                           0.124114   \n",
      "19          True  ...  [0.1528860330581665, 0.1502234935760498, 0.147...   \n",
      "20         False  ...  [0.1595240831375122, 0.16547036170959473, 0.16...   \n",
      "21         False  ...  [0.14935839176177979, 0.14352643489837646, 0.1...   \n",
      "22          True  ...  [0.1515723466873169, 0.15140199661254883, 0.15...   \n",
      "23         False  ...  [0.16299355030059814, 0.16282975673675537, 0.1...   \n",
      "24         False  ...  [0.15495610237121582, 0.15386247634887695, 0.1...   \n",
      "25         False  ...  [0.1662818193435669, 0.16605210304260254, 0.16...   \n",
      "26         False  ...  [0.16714608669281006, 0.16630911827087402, 0.1...   \n",
      "\n",
      "   student_memory  student_num_params  train_loss  val_loss  train_acc  \\\n",
      "0      512.221451          134.275780    0.012929  0.009959   0.995735   \n",
      "1       14.990440            3.904964    0.008659  0.154451   0.996895   \n",
      "2       14.990440            3.904964    0.026116  0.351365   0.996137   \n",
      "3       14.990440            3.904964    0.006984  0.049294   0.995208   \n",
      "4       14.990440            3.904964    0.053698  0.238034   0.997054   \n",
      "5       14.990440            3.904964    0.086460  0.317985   0.997599   \n",
      "6       14.990440            3.904964    0.056723  0.184061   0.997791   \n",
      "7       14.990440            3.904964    0.046669  0.183617   0.997855   \n",
      "8       16.142456            4.207156    0.010173  0.234677   0.996766   \n",
      "9       16.142456            4.207156    0.052385  0.227707   0.997374   \n",
      "10      16.142456            4.207156    0.068369  0.304788   0.997513   \n",
      "11      16.142456            4.207156    0.007126  0.055740   0.994450   \n",
      "12      16.142456            4.207156    0.012757  0.097381   0.998815   \n",
      "13       5.852264            1.521956    0.014167  0.274396   0.995165   \n",
      "14       5.852264            1.521956    0.018572  0.782709   0.997791   \n",
      "15       5.852264            1.521956    0.050203  0.243748   0.996894   \n",
      "16       5.852264            1.521956    0.005289  0.048387   0.996254   \n",
      "17       5.852264            1.521956    0.049678  0.169564   0.997310   \n",
      "18       5.852264            1.521956    0.075390  0.288699   0.997150   \n",
      "19       5.852264            1.521956    0.036826  0.173574   0.997855   \n",
      "20       4.859909            1.257704    0.006715  0.161494   0.997481   \n",
      "21       4.859909            1.257704    0.061004  0.265507   0.996895   \n",
      "22       4.859909            1.257704    0.045517  0.248109   0.997545   \n",
      "23       4.859909            1.257704    0.005810  0.053465   0.995806   \n",
      "24       4.859909            1.257704    0.103632  0.351772   0.990726   \n",
      "25       4.859909            1.257704    0.017416  0.140618   0.998335   \n",
      "26       4.859909            1.257704    0.092622  0.362567   0.996660   \n",
      "\n",
      "     val_acc  relative_val_loss  relative_val_acc  inference_speedup  \n",
      "0   0.995937           1.000000          1.000000           1.000000  \n",
      "1   0.964205          15.508722          0.968138           1.353126  \n",
      "2   0.937864          35.281309          0.941690           1.096474  \n",
      "3   0.967454           4.949689          0.971400           1.279624  \n",
      "4   0.969971          23.901459          0.973927           1.151499  \n",
      "5   0.967294          31.929519          0.971240           1.359911  \n",
      "6   0.970787          18.481934          0.974747           1.363370  \n",
      "7   0.970628          18.437363          0.974587           1.290612  \n",
      "8   0.952175          23.564405          0.956059           1.326626  \n",
      "9   0.965341          22.864563          0.969279           1.091929  \n",
      "10  0.968515          30.604386          0.972465           1.362598  \n",
      "11  0.958438           5.596940          0.962348           1.273883  \n",
      "12  0.975510           9.778259          0.979490           1.356744  \n",
      "13  0.938361          27.552645          0.942189           1.423360  \n",
      "14  0.886177          78.593493          0.889792           1.446088  \n",
      "15  0.967134          24.475267          0.971079           1.403423  \n",
      "16  0.969078           4.858668          0.973031           1.362432  \n",
      "17  0.971276          17.026256          0.975238           1.414045  \n",
      "18  0.971444          28.988829          0.975407           1.406322  \n",
      "19  0.972008          17.428972          0.975973           1.392323  \n",
      "20  0.965416          16.215930          0.969354           1.423697  \n",
      "21  0.964120          26.660079          0.968053           1.418148  \n",
      "22  0.966966          24.913151          0.970910           1.380457  \n",
      "23  0.964045           5.368508          0.967977           1.341726  \n",
      "24  0.958017          35.322211          0.961925           1.410341  \n",
      "25  0.969491          14.119795          0.973446           1.427332  \n",
      "26  0.967125          36.406155          0.971070           1.411487  \n",
      "\n",
      "[27 rows x 21 columns]\n",
      "(27, 21)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\andri\\OneDrive\\Desktop\\KD_AZ\\KnowledgeDistillation_AZ\\eval_experiments.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andri/OneDrive/Desktop/KD_AZ/KnowledgeDistillation_AZ/eval_experiments.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/andri/OneDrive/Desktop/KD_AZ/KnowledgeDistillation_AZ/eval_experiments.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m df_melted_model \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmelt(df, id_vars\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mstudent_model_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfull_model_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhyperparameters\u001b[39m\u001b[39m\"\u001b[39m], var_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m\"\u001b[39m, value_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/andri/OneDrive/Desktop/KD_AZ/KnowledgeDistillation_AZ/eval_experiments.ipynb#X12sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m df_melted_model[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_melted_model[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m   6236\u001b[0m     ]\n\u001b[0;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mastype(dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy, errors\u001b[39m=\u001b[39merrors)\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39mcopy, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    227\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    232\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\andri\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:170\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[0;32m    169\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(full_json)\n",
    "# df.insert(column=\"model_name\", loc=1, value=f\"{df['student_model_name']}_T={df['T']}_lossr={df['loss_ratio']}\")\n",
    "df.insert(loc=1, column='full_model_name', \n",
    "          value=df['student_model_name'] + \n",
    "                '_T=' + df['T'].astype(str) + \n",
    "                '_lossr=' + df['loss_ratio'].astype(str) + \n",
    "                '_cond=' + df['conditional'].astype(str) +\n",
    "                '_curr=' + df['curriculum'].astype(str) +\n",
    "                '_cosd=' + df['cosine_decay'].astype(str))\n",
    "df.insert(loc=2, column='hyperparameters', \n",
    "          value=np.where(df['curriculum'], \n",
    "                           # Add a string to numpy array of strings element-wise\n",
    "                           np.core.defchararray.add(\" Curr + \", np.where(df['cosine_decay'], \"Cos decay\", \"Lin decay\")),\n",
    "                           ' T=' + df['T'].astype(str)) +\n",
    "                  np.where(df['conditional'], \n",
    "                           \" Cond\", \n",
    "                           ' lossr=' + df['loss_ratio'].astype(str)))\n",
    "df.insert(loc=2, column='model_name', \n",
    "          value=df['student_model_name'] + df['hyperparameters'])\n",
    "df['student_num_params'] = df['student_num_params'] / 1e6\n",
    "df[\"relative_val_loss\"] = df[\"val_loss\"] / teacher_data[0][\"val_loss\"]\n",
    "df[\"relative_val_acc\"] = df[\"val_acc\"] / teacher_data[0][\"val_acc\"]\n",
    "df[\"inference_speedup\"] = teacher_data[0][\"inference_speed\"] / df[\"inference_speed\"]\n",
    "# Remove hyperparameters for teacher model\n",
    "df.loc[df['student_model_name'] == \"teacher_model\", [\"full_model_name\", \"model_name\", \"hyperparameters\"]] = \"Teacher model\"\n",
    "\n",
    "print(df.shape)\n",
    "# Filter batch size 256\n",
    "df = df[(df['model_name'] == 'teacher_model') | (df['bs'] == 256)].reset_index(drop=True)\n",
    "print(df)\n",
    "print(df.shape)\n",
    "\n",
    "df_melted_model = pd.melt(df, id_vars=[\"student_model_name\", \"full_model_name\", \"model_name\", \"hyperparameters\"], var_name=\"metric\", value_name=\"value\")\n",
    "df_melted_model['value'] = df_melted_model['value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(df, metric, model_group=\"All\", plot=False, legend_location=\"best\"):\n",
    "    if model_group.lower() == \"best\":\n",
    "        name_column = \"model_name\"\n",
    "        legend_name = \"Model name\"\n",
    "    else:\n",
    "        name_column = \"hyperparameters\"\n",
    "        legend_name = \"Hyperparameters\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='metric', y='value', hue=name_column, data=df)\n",
    "    plt.title(f'{model_group.capitalize()} models - {metric}')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend(title=legend_name, loc=legend_location)\n",
    "    plt.savefig(f'images/{metric.lower()}_{model_group}.png')\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_models(df, metric=\"Val loss\"):\n",
    "    # Find index of best metric for each student_model_name\n",
    "    grpd_values = df[df['metric'] == metric].groupby(['student_model_name'])['value']\n",
    "    # Min if loss, max if accuracy\n",
    "    best_idxs = grpd_values.idxmin() if \"loss\" in metric else grpd_values.idxmax()\n",
    "    \n",
    "    # Get corresponding student_model_name and hyperparameters from original DataFrame\n",
    "    best_models_info = df.loc[best_idxs, ['student_model_name', 'hyperparameters']]\n",
    "    \n",
    "    # Select all rows from original DataFrame that match student_model_name and hyperparameters of best models\n",
    "    return pd.merge(df, best_models_info, on=['student_model_name', 'hyperparameters'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted_losses = df_melted_model[df_melted_model[\"metric\"].isin(['train_loss', 'val_loss'])].copy()\n",
    "df_melted_losses['metric'] = [s.replace('_', ' ').capitalize() for s in df_melted_losses['metric']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(df=df_melted_losses[df_melted_losses[\"student_model_name\"].isin([\"teacher_model\", \"ghostnet\"])], \n",
    "             metric=\"Loss\", model_group=\"ghostnet\", plot=False)\n",
    "plot_metrics(df=df_melted_losses[df_melted_losses[\"student_model_name\"].isin([\"teacher_model\", \"mobilenet-V3-large\"])], \n",
    "             metric=\"Loss\", model_group=\"mobilenet-V3-large\", plot=False)\n",
    "plot_metrics(df=df_melted_losses[df_melted_losses[\"student_model_name\"].isin([\"teacher_model\", \"mobilenet-V3-small\"])], \n",
    "             metric=\"Loss\", model_group=\"mobilenet-V3-small\", plot=False)\n",
    "plot_metrics(df=df_melted_losses[df_melted_losses[\"student_model_name\"].isin([\"teacher_model\", \"shufflenet\"])], \n",
    "             metric=\"Loss\", model_group=\"shufflenet\", plot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_losses_df = get_best_models(df=df_melted_losses, metric=\"Val loss\")\n",
    "plot_metrics(df=best_losses_df, metric=\"Loss\", model_group=\"Best\", plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_melted_accs = df_melted_model[df_melted_model[\"metric\"].isin(['train_acc', 'val_acc', 'relative_val_acc'])].copy()\n",
    "df_melted_accs = df_melted_model[df_melted_model[\"metric\"].isin(['train_acc', 'val_acc'])].copy()\n",
    "df_melted_accs['metric'] = [s.replace('_', ' ').capitalize() for s in df_melted_accs['metric']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(df=df_melted_accs[df_melted_accs[\"student_model_name\"].isin([\"teacher_model\", \"ghostnet\"])], \n",
    "             metric=\"Accuracy\", model_group=\"ghostnet\", plot=False, legend_location=\"lower center\")\n",
    "plot_metrics(df=df_melted_accs[df_melted_accs[\"student_model_name\"].isin([\"teacher_model\", \"mobilenet-V3-large\"])], \n",
    "             metric=\"Accuracy\", model_group=\"mobilenet-V3-large\", plot=False, legend_location=\"lower center\")\n",
    "plot_metrics(df=df_melted_accs[df_melted_accs[\"student_model_name\"].isin([\"teacher_model\", \"mobilenet-V3-small\"])], \n",
    "             metric=\"Accuracy\", model_group=\"mobilenet-V3-small\", plot=False, legend_location=\"lower center\")\n",
    "plot_metrics(df=df_melted_accs[df_melted_accs[\"student_model_name\"].isin([\"teacher_model\", \"shufflenet\"])], \n",
    "             metric=\"Accuracy\", model_group=\"shufflenet\", plot=False, legend_location=\"lower center\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accs_df = get_best_models(df=df_melted_accs, metric=\"Val acc\")\n",
    "plot_metrics(df=best_accs_df, metric=\"Accuracy\", model_group=\"Best\", plot=False, legend_location=\"lower center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plots for model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(s):\n",
    "    \"\"\"\n",
    "    Helper function to check if string can be converted to float.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def scatterplot_compare(df, model_group=\"All\", plot=False, model_name_pos=\"lower right\", model_size_pos=\"upper left\"):\n",
    "    # Create a scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "\n",
    "    if model_group.lower() == \"best\":\n",
    "        name_column = \"model_name\"\n",
    "        legend_name = \"Model name\"\n",
    "    else:\n",
    "        name_column = \"hyperparameters\"\n",
    "        legend_name = \"Hyperparameters\"\n",
    "\n",
    "    # Create a color palette\n",
    "    palette = sns.color_palette(\"hls\", df[name_column].nunique())\n",
    "    \n",
    "    scatter = sns.scatterplot(data=df, x='inference_speedup', y='relative_val_acc', \n",
    "                              size='student_memory', sizes=(50, 200), \n",
    "                              hue=name_column, palette=palette)\n",
    "\n",
    "    plt.xlim(left=1)\n",
    "    plt.ylim(top=1)\n",
    "\n",
    "    # Get labels of double legend\n",
    "    handles, labels = scatter.get_legend_handles_labels()\n",
    "    # Round model sizes and add MB, leave model names as is\n",
    "    labels = [f'{round(float(label), 1)} MB' if is_float(label) else label for label in labels]\n",
    "    \n",
    "    # Create two legends: one for size and one for model name (hue)\n",
    "    size_legend = plt.legend(handles[-len(df['student_memory'].unique()):], \n",
    "                             labels[-len(df['student_memory'].unique()):], \n",
    "                             title='Model size (MB)', loc=model_size_pos)\n",
    "    color_legend = plt.legend(handles[1:len(df[name_column].unique())+1], \n",
    "                              labels[1:len(df[name_column].unique())+1], \n",
    "                              title=legend_name, loc=model_name_pos)\n",
    "    \n",
    "    # Add the other legend\n",
    "    plt.gca().add_artist(size_legend)\n",
    "\n",
    "    plt.title(f'{model_group.capitalize()} models')\n",
    "    plt.xlabel('Inference Speedup')\n",
    "    plt.ylabel('Relative Validation Accuracy')\n",
    "    plt.savefig(f'images/fat_plot_{model_group}.png')\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "         plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_name in df[\"student_model_name\"].unique()[1:]:\n",
    "#     print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot_compare(df=df[df[\"student_model_name\"].isin([\"ghostnet\"])], \n",
    "                    model_group=\"ghostnet\", plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot_compare(df=df[df[\"student_model_name\"].isin([\"mobilenet-V3-large\"])], \n",
    "                    model_group=\"mobilenet-V3-large\", plot=True,\n",
    "                    model_name_pos=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot_compare(df=df[df[\"student_model_name\"].isin([\"mobilenet-V3-small\"])], \n",
    "                    model_group=\"mobilenet-V3-small\", plot=True,\n",
    "                    model_name_pos=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot_compare(df=df[df[\"student_model_name\"].isin([\"shufflenet\"])], \n",
    "                    model_group=\"shufflenet\", plot=True,\n",
    "                    model_name_pos=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for best model (based on val acc) of each architecture\n",
    "best_df = df.loc[df.groupby('student_model_name')['val_acc'].idxmax()].reset_index(drop=True)\n",
    "best_df = best_df[best_df[\"student_model_name\"] != \"teacher_model\"] # exclude teacher model\n",
    "scatterplot_compare(best_df, model_group=\"best\", plot=True,\n",
    "                    model_name_pos=\"lower left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
